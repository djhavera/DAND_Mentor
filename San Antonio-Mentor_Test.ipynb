{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"san-antonio_texas.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounds': 1,\n",
       " 'member': 23537,\n",
       " 'nd': 1479783,\n",
       " 'node': 1244193,\n",
       " 'osm': 1,\n",
       " 'relation': 1718,\n",
       " 'tag': 751039,\n",
       " 'way': 144603}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if elem.tag in tags.keys():\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "\n",
    "    return tags\n",
    "\n",
    "count_tags(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some regular expressions\n",
    "import pprint\n",
    "import re\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "postcode_re = re.compile(r'^\\d{5}$')\n",
    " \n",
    "# expected street names\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \"Trail\", \"Parkway\",\n",
    "            \"Commons\",\"Bend\",\"Causeway\", \"Circle\",\"Concession\",\"County\",\"Drive\",\"Highway\",\"Manor\",\"Passage\",\"Path\",\"Plaza\",\n",
    "            \"Point\",\"Terrace\",\"Trail\",\"Way\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {\"AVE\":\"Avenue\",\"Ave\":\"Avenue\",\"Ave.\":\"Avenue\",\"ave\":\"Avenue\" ,\"avenue\":\"Avenue\",\n",
    "    \"BLVD\":\"Boulevard\", \"Blvd\":\"Boulevard\",\"Blvd.\":\"Boulevard\",\"Bnd\":\"Bend\",\n",
    "        \"Cir\": \"Circle\",\"Cirlce\":\"Circle\",\"Ct\":\"County\",\"Cv\":\"County\",\"ct\":\"County\",\n",
    "            \"DRIVE\":\"Drive\",\"Dr\":\"Drive\",\"Dr.\":\"Drive\",\"E\":\"Drive\",\n",
    "                \"Hwy\":\"Highway\",\"Ln\":\"Lane\",\"Mnr\":\"Manor\",\"North\":\"Drive\",\n",
    "                    \"Pkwy\":\"Parkway\",\"Poinciana\":\"Point\",\"Pt\":\"Point\",\n",
    "                        \"RD\":\"Road\",\"Rd.\":\"Road\",\"Rd\":\"Road\",\"rd\":\"Road\",\"road\":\"Road\",\n",
    "                            \"ST\":\"Street\",\"St\":\"Street\",\"St.\":\"Street\",\"st\":\"Street\",\n",
    "                                \"Ter\":\"Terrace\",\"W\":\"Way\", \"Trl\":\"Trail\",\n",
    "                                    \"okeechobee\":\"Okeechobee Road\",\"street\":\"Street\",\"US Highway 1\":\"US Highway\",\"3331\": \"33310\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_street_type(street_types, street_name):\n",
    "    # Function to add street names not in the common_street_types list\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_street_name(elem):\n",
    "    # To determine if an element is a street name\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def audit_street(osmfile):\n",
    "    # iter through all street name tag under node or way and audit the street name value\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()#####\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'100': set(['W Ave #100']),\n",
      " '103': set(['Broadway St #103']),\n",
      " '112': set(['US Hwy 281 North, Suite 112']),\n",
      " '12': set(['RM 12']),\n",
      " '1346': set(['FM 1346']),\n",
      " '151': set(['State Highway 151']),\n",
      " '2011': set(['Huebner Rd #2011']),\n",
      " '281': set(['North US Highway 281']),\n",
      " '3351': set(['Farm-to-Market Road 3351']),\n",
      " '35': set(['North IH 35',\n",
      "            'North Interstate Highway 35',\n",
      "            'South Interstate Highway 35']),\n",
      " '410': set(['Northeast Loop 410', 'Northwest Loop 410']),\n",
      " '46': set(['North State Highway 46', 'State Highway 46']),\n",
      " '464': set(['FM 464']),\n",
      " '775': set(['FM 775']),\n",
      " '78': set(['Farm-to-Market Road 78']),\n",
      " 'A': set(['Avenue A']),\n",
      " 'Audrey': set(['Ashton Audrey']),\n",
      " 'B': set(['Avenue B']),\n",
      " 'Bay': set(['Bourdeaux Bay', 'Goldenrain Bay']),\n",
      " 'Bluff': set(['River Bluff']),\n",
      " 'Bois': set(['Clos Du Bois']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'Bypass': set(['North Highway 123 Bypass']),\n",
      " 'C': set(['Avenue C']),\n",
      " 'Casbury': set(['Casbury']),\n",
      " 'Cedar': set(['Gray Cedar']),\n",
      " 'Coach': set(['Dunhill Coach']),\n",
      " 'Corral': set(['Cooper Corral']),\n",
      " 'Cove': set(['Dream Cove', 'Oakview Cove', 'Rustling Cove', 'Seal Cove']),\n",
      " 'Creek': set(['Buck Creek',\n",
      "               'Cloudy Creek',\n",
      "               'Cougar Creek',\n",
      "               'Emerald Creek',\n",
      "               'Flint Creek',\n",
      "               'Kiowa Creek',\n",
      "               'Low Creek',\n",
      "               'Perrin Creek',\n",
      "               'Pipers Creek',\n",
      "               'Shuman Creek',\n",
      "               'Silent Creek',\n",
      "               'Taos Creek',\n",
      "               'Treaty Creek',\n",
      "               'Wayside Creek',\n",
      "               'White Creek']),\n",
      " 'Crest': set(['Daylight Crest', 'Magnolia Crest']),\n",
      " 'Crossing': set(['Zuehl Crossing']),\n",
      " 'D': set(['Avenue D', 'NW Loop 410, Ste D']),\n",
      " 'Dawn': set(['April Dawn', 'Enchanted Dawn']),\n",
      " 'Depot': set(['Midway Depot']),\n",
      " 'Dolorosa': set(['Dolorosa']),\n",
      " 'Dr': set(['Sea World Dr']),\n",
      " 'East': set(['Interstate Highway 10 East', 'North Loop 1604 East']),\n",
      " 'End': set(['Coves End']),\n",
      " 'Falls': set(['Alomosa Falls', 'Elise Falls']),\n",
      " 'Field': set(['Magnolia Field', 'Royal Field']),\n",
      " 'Gap': set(['Drew Gap']),\n",
      " 'Gardendale': set(['Gardendale']),\n",
      " 'Gate': set(['Balcones Gate']),\n",
      " 'Glade': set(['Pebble Glade']),\n",
      " 'H10C': set(['NW Loop 410 Space H10C']),\n",
      " 'Hill': set(['Chalk Hill', 'Magnolia Hill']),\n",
      " 'Home': set(['Sutter Home']),\n",
      " 'Inglenook': set(['Inglenook']),\n",
      " 'Knoll': set(['Amber Knoll']),\n",
      " 'Krug': set(['Daniel Krug']),\n",
      " 'Leap': set(['Frogs Leap', 'Stags Leap']),\n",
      " 'Loop': set(['Grand Loop']),\n",
      " 'Martinelli': set(['Martinelli']),\n",
      " 'Mesa': set(['Osage Mesa']),\n",
      " 'Mill': set(['Border Mill', 'Cooper Mill']),\n",
      " 'Mist': set(['Emerald Mist', 'Magnolia Mist', 'Vineyard Mist']),\n",
      " 'Mondavi': set(['Robert Mondavi']),\n",
      " 'Moon': set(['Sycamore Moon']),\n",
      " 'North': set(['East Loop 1604 North',\n",
      "               'Interstate Highway 35 North',\n",
      "               'West Loop 1604 North']),\n",
      " 'Oak': set(['Haven Oak', 'Soaring Oak', 'Wilderness Oak']),\n",
      " 'Oaks': set(['Alto Oaks',\n",
      "              'Ancient Oaks',\n",
      "              'Bay Oaks',\n",
      "              'Cypress Oaks',\n",
      "              'Echoing Oaks',\n",
      "              'Huebner Oaks',\n",
      "              'Jalane Oaks',\n",
      "              'Paseo Oaks',\n",
      "              'Winston Oaks']),\n",
      " 'Palm': set(['Windmill Palm']),\n",
      " 'Park': set(['Enero Park',\n",
      "              'Jalane Park',\n",
      "              'Mancero Park',\n",
      "              'Newoak Park',\n",
      "              'Sutters Park',\n",
      "              'Woodrose Park']),\n",
      " 'Parkford': set(['Parkford']),\n",
      " 'Pass': set(['Cooper Pass',\n",
      "              'Grapevine Pass',\n",
      "              'Heritage Pass',\n",
      "              'Limestone Pass',\n",
      "              'Paisano Pass',\n",
      "              'Walnut Pass',\n",
      "              'Woodland Pass']),\n",
      " 'Peak': set(['Buffalo Peak', 'Geyser Peak', 'Palo Duro Peak']),\n",
      " 'Phelps': set(['Joseph Phelps']),\n",
      " 'Pointe': set(['Azalea Pointe']),\n",
      " 'Rafanelli': set(['Rafanelli']),\n",
      " 'Ranch': set(['Reid Ranch', 'River Ranch', 'Stephens Ranch']),\n",
      " 'Rhapsody': set(['West Rhapsody']),\n",
      " 'Ridge': set(['Chestnut Ridge',\n",
      "               'Cougar Ridge',\n",
      "               'Daylight Ridge',\n",
      "               'Encanto Ridge',\n",
      "               'Raven Ridge',\n",
      "               'Rocky Ridge',\n",
      "               'Stormy Ridge',\n",
      "               'Thomas Ridge']),\n",
      " 'River': set(['Magnolia River']),\n",
      " 'Rock': set(['Painted Rock', 'Silver Rock', 'Stormy Rock']),\n",
      " 'Rosemoss': set(['Rosemoss']),\n",
      " 'Route': set(['Cimarron Route']),\n",
      " 'Row': set(['University Row']),\n",
      " 'Run': set(['Collenback Run',\n",
      "             'Daisy Run',\n",
      "             'Magnolia Run',\n",
      "             'Piney Wood Run',\n",
      "             'Shelbys Run',\n",
      "             'Wild Horse Run']),\n",
      " 'S': set(['Interstate 35 S']),\n",
      " 'Saintsbury': set(['Saintsbury']),\n",
      " 'Sonoma': set(['Piper Sonoma']),\n",
      " 'Springs': set(['Coral Springs', 'Flora Springs']),\n",
      " 'St': set(['W Commerce St', 'W Josephine St']),\n",
      " 'Stage': set(['Brazos Stage', 'Calvary Stage', 'Midnight Stage']),\n",
      " 'Star': set(['Mountain Star']),\n",
      " 'Summit': set(['Magnolia Summit']),\n",
      " 'Sunset': set(['Pecos Sunset']),\n",
      " 'Top': set(['Mountain Top']),\n",
      " 'Trace': set(['Woodland Trace']),\n",
      " 'Trolley': set(['Golden Trolley']),\n",
      " 'Vail': set(['Summer Vail']),\n",
      " 'Valet': set(['Vista Valet']),\n",
      " 'Valley': set(['Cooper Valley']),\n",
      " 'View': set(['Cap Rock View', 'Chappel View']),\n",
      " 'Vista': set(['Dillons Vista']),\n",
      " 'West': set(['IH-10 West',\n",
      "              'Interstate Highway 10 West',\n",
      "              'North Loop 1604 West']),\n",
      " 'Willow': set(['Brandon Willow']),\n",
      " 'Woods': set(['Blanco Woods'])}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dict(audit_street(SAMPLE_FILE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "process_map(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_post_code(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_postcode_type(postcode_types, postcode):\n",
    "    m = postcode_re.search(postcode)\n",
    "    if m:\n",
    "        # pc = len(m.group(0))\n",
    "        pc = m.group()\n",
    "        postcode_types[pc].add(postcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit_postcode(osmfile):\n",
    "    # iter through all street name tag under node or way and audit the street name value\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    postcode_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_post_code(tag):\n",
    "                    audit_postcode_type(postcode_types, tag.attrib['v'])\n",
    "    return postcode_types\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'78006': set(['78006']),\n",
      " '78023': set(['78023']),\n",
      " '78052': set(['78052']),\n",
      " '78070': set(['78070']),\n",
      " '78108': set(['78108']),\n",
      " '78109': set(['78109']),\n",
      " '78112': set(['78112']),\n",
      " '78114': set(['78114']),\n",
      " '78121': set(['78121']),\n",
      " '78130': set(['78130']),\n",
      " '78154': set(['78154']),\n",
      " '78155': set(['78155']),\n",
      " '78204': set(['78204']),\n",
      " '78205': set(['78205']),\n",
      " '78207': set(['78207']),\n",
      " '78209': set(['78209']),\n",
      " '78210': set(['78210']),\n",
      " '78211': set(['78211']),\n",
      " '78212': set(['78212']),\n",
      " '78213': set(['78213']),\n",
      " '78216': set(['78216']),\n",
      " '78217': set(['78217']),\n",
      " '78218': set(['78218']),\n",
      " '78219': set(['78219']),\n",
      " '78222': set(['78222']),\n",
      " '78223': set(['78223']),\n",
      " '78226': set(['78226']),\n",
      " '78227': set(['78227']),\n",
      " '78228': set(['78228']),\n",
      " '78229': set(['78229']),\n",
      " '78230': set(['78230']),\n",
      " '78231': set(['78231']),\n",
      " '78232': set(['78232']),\n",
      " '78233': set(['78233']),\n",
      " '78238': set(['78238']),\n",
      " '78239': set(['78239']),\n",
      " '78240': set(['78240']),\n",
      " '78244': set(['78244']),\n",
      " '78245': set(['78245']),\n",
      " '78247': set(['78247']),\n",
      " '78248': set(['78248']),\n",
      " '78249': set(['78249']),\n",
      " '78250': set(['78250']),\n",
      " '78251': set(['78251']),\n",
      " '78253': set(['78253']),\n",
      " '78254': set(['78254']),\n",
      " '78255': set(['78255']),\n",
      " '78256': set(['78256']),\n",
      " '78257': set(['78257']),\n",
      " '78258': set(['78258']),\n",
      " '78260': set(['78260']),\n",
      " '78261': set(['78261']),\n",
      " '78288': set(['78288']),\n",
      " '78648': set(['78648']),\n",
      " '78666': set(['78666'])}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(dict(audit_postcode(SAMPLE_FILE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_postcode(postcode, mapping):\n",
    "   \n",
    "    m = re.findall(r'^(\\d{5})-\\d{4}$', postcode)\n",
    "   \n",
    "    if m:\n",
    "        postcode = m[0]\n",
    "    elif postcode in mapping:\n",
    "        postcode = mapping[postcode]\n",
    "   \n",
    "    return postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m.group() not in expected:\n",
    "        if m.group() in mapping.keys():\n",
    "            print \"BEFORE\"\n",
    "            print name\n",
    "            name = re.sub(m.group(), mapping[m.group()], name)\n",
    "            print \"AFTER\"\n",
    "            print name\n",
    "            \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"sample.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "   \n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "   \n",
    "    if element.tag == 'node':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in NODE_FIELDS:\n",
    "                node_attribs[attrib] = element.attrib[attrib]\n",
    "       \n",
    "        for child in element:\n",
    "            node_tag = {}\n",
    "            if LOWER_COLON.match(child.attrib['k']):\n",
    "                node_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "                node_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = child.attrib['v']\n",
    "                if child.attrib['k'] == 'addr:street':\n",
    "                    # check if your function returns a value\n",
    "                    if update_name(child.attrib[\"v\"], mapping):\n",
    "                        node_tag[\"value\"] = update_name(child.attrib[\"v\"], mapping)\n",
    "                    else:\n",
    "                        continue\n",
    "                #elif child.attrib['k'] == 'addr:postcode':\n",
    "                    # check if your function returns a value\n",
    "                #    if update_postcode(child.attrib['v']):\n",
    "                #        tag['value'] = update_postcode(child.attrib['v'])\n",
    "                #    else:\n",
    "                        continue\n",
    "                tags.append(node_tag)\n",
    "            elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                continue\n",
    "            else:\n",
    "                node_tag['type'] = 'regular'\n",
    "                node_tag['key'] = child.attrib['k']\n",
    "                node_tag['id'] = element.attrib['id']\n",
    "                node_tag['value'] = child.attrib['v']\n",
    "                tags.append(node_tag)\n",
    "       \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    " \n",
    "    elif element.tag == 'way':\n",
    "        for attrib in element.attrib:\n",
    "            if attrib in WAY_FIELDS:\n",
    "                way_attribs[attrib] = element.attrib[attrib]\n",
    "       \n",
    "        position = 0\n",
    "        for child in element:\n",
    "            way_tag = {}\n",
    "            way_node = {}\n",
    "           \n",
    "            if child.tag == 'tag':\n",
    "                if LOWER_COLON.match(child.attrib['k']):\n",
    "                    way_tag['type'] = child.attrib['k'].split(':',1)[0]\n",
    "                    way_tag['key'] = child.attrib['k'].split(':',1)[1]\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    if child.attrib[\"k\"] == 'addr:street':\n",
    "                    # check if your function returns a value\n",
    "                        if update_name(child.attrib[\"v\"], mapping):\n",
    "                            way_tag[\"value\"] = update_name(child.attrib[\"v\"], mapping)\n",
    "                        else:\n",
    "                            continue\n",
    "       \n",
    "                #elif child.attrib['k'] == 'addr:postcode':\n",
    "                # check if your function returns a value\n",
    "                #    if update_postcode(child.attrib['v']):\n",
    "                #        tag['value'] = update_postcode(child.attrib['v'])\n",
    "                #    else:\n",
    "                #        continue\n",
    "                    tags.append(way_tag)\n",
    "                elif PROBLEMCHARS.match(child.attrib['k']):\n",
    "                    continue\n",
    "                else:\n",
    "                    way_tag['type'] = 'regular'\n",
    "                    way_tag['key'] = child.attrib['k']\n",
    "                    way_tag['id'] = element.attrib['id']\n",
    "                    way_tag['value'] = child.attrib['v']\n",
    "                    tags.append(way_tag)\n",
    "       \n",
    "            elif child.tag == 'nd':\n",
    "                way_node['id'] = element.attrib['id']\n",
    "                way_node['node_id'] = child.attrib['ref']\n",
    "                way_node['position'] = position\n",
    "                position += 1\n",
    "                way_nodes.append(way_node)\n",
    " \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE\n",
      "Interstate Highway 35 North\n",
      "AFTER\n",
      "Interstate Highway 35 Drive\n",
      "BEFORE\n",
      "Interstate Highway 35 North\n",
      "AFTER\n",
      "Interstate Highway 35 Drive\n",
      "BEFORE\n",
      "W Josephine St\n",
      "AFTER\n",
      "W Josephine Street\n",
      "BEFORE\n",
      "W Josephine St\n",
      "AFTER\n",
      "W Josephine Street\n",
      "BEFORE\n",
      "W Commerce St\n",
      "AFTER\n",
      "W Commerce Street\n",
      "BEFORE\n",
      "W Commerce St\n",
      "AFTER\n",
      "W Commerce Street\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "West Loop 1604 North\n",
      "AFTER\n",
      "West Loop 1604 Drive\n",
      "BEFORE\n",
      "East Loop 1604 North\n",
      "AFTER\n",
      "East Loop 1604 Drive\n",
      "BEFORE\n",
      "East Loop 1604 North\n",
      "AFTER\n",
      "East Loop 1604 Drive\n",
      "BEFORE\n",
      "Interstate Highway 35 North\n",
      "AFTER\n",
      "Interstate Highway 35 Drive\n",
      "BEFORE\n",
      "Interstate Highway 35 North\n",
      "AFTER\n",
      "Interstate Highway 35 Drive\n",
      "BEFORE\n",
      "Sea World Dr\n",
      "AFTER\n",
      "Sea World Drive\n",
      "BEFORE\n",
      "Sea World Dr\n",
      "AFTER\n",
      "Sea World Drive\n"
     ]
    }
   ],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
